#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 3cm
\rightmargin 3cm
\bottommargin 3cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
K-Fold Cross-Validation
\end_layout

\begin_layout Standard
Consider the joint optimization problem to find the best regularization
 parameter 
\begin_inset Formula $\lambda$
\end_inset

 in 
\begin_inset Formula $\Lambda$
\end_inset

 via 
\begin_inset Formula $K$
\end_inset

-fold cross validation.
 Let 
\begin_inset Formula $D$
\end_inset

 be the entire dataset (so both 
\begin_inset Formula $y,X$
\end_inset

).
 For 
\begin_inset Formula $k=1,...,K$
\end_inset

, let 
\begin_inset Formula $D_{k}$
\end_inset

 represent the 
\begin_inset Formula $k$
\end_inset

th fold and 
\begin_inset Formula $D_{-k}$
\end_inset

 denote all the folds minus the 
\begin_inset Formula $k$
\end_inset

th fold.
 For a given 
\begin_inset Formula $\lambda$
\end_inset

, train over 
\begin_inset Formula $D_{-k}$
\end_inset

 and then validate over 
\begin_inset Formula $D_{k}$
\end_inset

.
 Let the number of observations for each fold be 
\begin_inset Formula $n_{k}$
\end_inset

 and let the total number of observations be 
\begin_inset Formula $n$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\|h\|_{k}^{2}=\frac{1}{n_{k}}\sum_{i\in D_{k}}h(x_{i})^{2}$
\end_inset

 and similarly for 
\begin_inset Formula $\|h\|_{-k}^{2}$
\end_inset

 for the set 
\begin_inset Formula $D_{-k}$
\end_inset

 and 
\begin_inset Formula $\|h\|_{D}^{2}$
\end_inset

 for the set 
\begin_inset Formula $D$
\end_inset

.
 Let 
\begin_inset Formula $\langle h,g\rangle_{k}=\frac{1}{n_{k}}\sum_{i\in D_{k}}h(x_{i})g(x_{i})$
\end_inset

 and 
\begin_inset Formula $\langle h,g\rangle_{-k}$
\end_inset

 for the set 
\begin_inset Formula $D_{-k}$
\end_inset

 and 
\begin_inset Formula $\langle h,g\rangle_{D}$
\end_inset

 for the set 
\begin_inset Formula $D$
\end_inset

.
\end_layout

\begin_layout Standard
Let us define
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{\lambda}=\arg\min_{\lambda\in\Lambda}\frac{1}{2}\|y-\hat{g}_{\lambda}(\cdot|D_{-k})\|_{k}^{2}
\]

\end_inset


\begin_inset Formula 
\[
\hat{g}(\lambda|D_{-k})=\arg\min_{g\in\mathcal{G}}\frac{1}{2}\|y-g\|_{-k}^{2}+\lambda\left(P(g)+\frac{w}{2}\|g\|_{D}^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The 
\begin_inset Formula $K$
\end_inset

-fold CV model is 
\begin_inset Formula 
\[
\hat{g}(\lambda|D)=\arg\min_{g\in\mathcal{G}}\frac{1}{2}\|y-g\|_{D}^{2}+\lambda\left(P(g)+\frac{w}{2}\|g\|_{D}^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Let the range of 
\begin_inset Formula $\Lambda$
\end_inset

 be from 
\begin_inset Formula $\lambda_{min}=O_{P}(n^{-\tau_{min}})$
\end_inset

 to 
\begin_inset Formula $\lambda_{max}=O_{P}(1)]$
\end_inset

.
\end_layout

\begin_layout Standard
We show that 
\begin_inset Formula 
\[
\|\hat{g}_{\hat{\lambda}}(\cdot|D)-g^{*}\|_{D}\le???????+\sum_{k=1}^{K}\|g^{*}-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Notation
\end_layout

\begin_layout Standard
\begin_inset Formula $a\lesssim b$
\end_inset

 means that 
\begin_inset Formula $a\le Cb+c$
\end_inset

 where 
\begin_inset Formula $C>0,c$
\end_inset

 are constants independent of 
\begin_inset Formula $n$
\end_inset

.
\end_layout

\begin_layout Section
Proof
\end_layout

\begin_layout Standard
The proof is based on two main ideas.
\end_layout

\begin_layout Standard
First, we bound the error of the retrained 
\begin_inset Formula $K$
\end_inset

-fold CV model by a convex combination of the 
\begin_inset Formula $K$
\end_inset

 trained models from each fold.
\end_layout

\begin_layout Standard
Second, the additional ridge regression penalty allows us to bound the entropy
 of 
\begin_inset Formula $\hat{\mathcal{G}}(D_{-k})=\left\{ \hat{g}_{\lambda}(\cdot|D_{-k}):\lambda\in\Lambda\right\} $
\end_inset

, which in turn allows us to bound empirical and Rademacher processes.
\end_layout

\begin_layout Subsubsection*

\series bold
Step 1:
\end_layout

\begin_layout Standard
Define the convex combination 
\begin_inset Formula 
\[
\hat{\xi}_{\lambda}(x)=\frac{1}{K-1}\sum_{k=1}^{K}\frac{n-n_{k}}{n}\hat{g}_{\lambda}(x|D_{-k})
\]

\end_inset


\end_layout

\begin_layout Standard
By the triangle inequality,
\begin_inset Formula 
\begin{eqnarray*}
\|\hat{g}_{\hat{\lambda}}(\cdot|D)-g^{*}\|_{D} & \le & \|\hat{g}_{\hat{\lambda}}(\cdot|D)-\xi_{\hat{\lambda}}\|_{D}+\|\xi_{\hat{\lambda}}-\xi_{\tilde{\lambda}}\|_{D}+\|\xi_{\tilde{\lambda}}-g^{*}\|_{D}\\
 & \le & \|\hat{g}_{\hat{\lambda}}(\cdot|D)-\xi_{\hat{\lambda}}\|_{D}+\frac{1}{K-1}\sum_{k=1}^{K}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{D}+\|\xi_{\tilde{\lambda}}-g^{*}\|_{D}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
We bound the first, second, and third summands in steps 2, 3, and 4, respectivel
y.
\end_layout

\begin_layout Subsubsection*
Step 2: Bound 
\begin_inset Formula $\|\hat{g}_{\hat{\lambda}}(\cdot|D)-\xi_{\hat{\lambda}}\|_{D}$
\end_inset


\end_layout

\begin_layout Standard
Adding the two inequalities from Lemma 1 and 2, we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\|\hat{g}_{\lambda}(\cdot|D)-\hat{\xi}_{\lambda}\|_{D}^{2}\le\frac{1}{K-1}\sum\frac{n-n_{k}}{n}\left(\left|\langle\epsilon,\hat{\xi}_{\lambda}-\hat{g}_{\lambda}(\cdot|D_{-k})\rangle_{-k}\right|+\left|\langle g^{*}-\hat{\xi}_{\lambda},\hat{\xi}_{\lambda}-\hat{g}_{\lambda}(\cdot|D_{-k})\rangle_{k}\right|\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The first term is bounded by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\left|\langle\epsilon,\hat{\xi}_{\lambda}-\hat{g}_{\lambda}(\cdot|D_{-k})\rangle_{-k}\right| & = & \left|\langle\epsilon,\frac{1}{K-1}\sum_{\ell=1}^{K}\frac{n-n_{\ell}}{n}\hat{g}_{\lambda}(\cdot|D_{-\ell})-\hat{g}_{\lambda}(\cdot|D_{-k})\rangle_{-k}\right|\\
 & \lesssim & \sum_{\ell=1}^{K}\left|\langle\epsilon,\hat{g}_{\lambda}(\cdot|D_{-\ell})-g^{*}\rangle_{-k}\right|
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
By Lemma 4, we know that 
\begin_inset Formula $\sup_{\lambda}\|\hat{g}_{\lambda}(\cdot|D_{-\ell})-g^{*}\|\le F\sigma$
\end_inset

.
 Hence by Lemma 3, we have that for all 
\begin_inset Formula $\delta\ge CR\sqrt{J}\left(\frac{1+\log(C/\sqrt{w})+\kappa\log n}{n-n_{k}}\right)^{1/2}$
\end_inset

, we have for all 
\begin_inset Formula $\ell=1:K$
\end_inset

 and 
\begin_inset Formula $k=1:K$
\end_inset

, 
\begin_inset Formula 
\[
Pr\left(\sup_{\lambda}\left|\langle\epsilon,\hat{g}_{\lambda}(\cdot|D_{-\ell})-g^{*}\rangle_{-k}\right|\ge\delta\wedge\|\epsilon\|_{-k}\le2\sigma\right)\le C\exp\left(-(n-n_{k})\frac{\delta^{2}}{C^{2}R^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The second term is bounded by 
\begin_inset Formula 
\begin{eqnarray*}
 &  & \left|\langle g^{*}-\hat{\xi}_{\lambda},\hat{\xi}_{\lambda}-\hat{g}_{\lambda}(\cdot|D_{-k})\rangle_{k}\right|\\
 & \le & \left|\left\langle \frac{1}{K-1}\sum_{\ell=1}^{K}\frac{n-n_{\ell}}{n}\left(g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right),\frac{1}{K-1}\sum_{\ell=1}^{K}\frac{n-n_{\ell}}{n}\left(g^{*}-\hat{\xi}_{\lambda}\right)+\hat{g}_{\lambda}(\cdot|D_{-k})-g^{*}\right\rangle _{k}\right|\\
 & \apprle & \frac{1}{K-1}\sum_{\ell=1}^{K}\frac{n-n_{k}}{n}\left\Vert g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right\Vert _{-k}^{2}\\
 & \le & \frac{1}{K-1}\sum_{\ell=1}^{K}\frac{n-n_{k}}{n}\sum_{h\ne k}\frac{n_{h}}{n-n_{k}}\left\Vert g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right\Vert _{h}^{2}\\
 & \apprle & \sum_{\ell=1}^{K}\left\Vert g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right\Vert _{\ell}^{2}+\left(\left\Vert g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right\Vert _{h}^{2}-\left\Vert g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right\Vert _{\ell}^{2}\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
We will use a symmetrization argument to bound the term in the parenthesis.
 Let 
\begin_inset Formula $W_{i}$
\end_inset

 be RV s.t.
 
\begin_inset Formula $Pr(W_{i}=1)=\frac{n_{h}}{n_{h}+n_{k}}$
\end_inset

 and 
\begin_inset Formula $Pr(W_{i}=-\frac{n_{h}+n_{k}}{n_{k}})=\frac{n_{k}}{n_{h}+n_{k}}$
\end_inset

 (so 
\begin_inset Formula $EW_{i}=0$
\end_inset

).
 We have 
\begin_inset Formula 
\begin{eqnarray*}
 &  & Pr_{X_{h},X_{\ell}}\left(\left\Vert g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right\Vert _{h}^{2}-\left\Vert g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right\Vert _{\ell}^{2}\ge\delta\right)\\
 & \le & 2Pr_{W,X_{h},X_{\ell}}\left(\sup_{\lambda}\frac{1}{n_{h}+n_{\ell}}\sum_{i\in D_{h}\cup D_{\ell}}W_{i}\left(g^{*}(x_{i})-\hat{g}_{\lambda}(x_{i}|D_{-\ell})\right)^{2}\ge\delta/2\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
where the second inequality follows from a symmetrization argument (check
 this!)
\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $W_{i}$
\end_inset

 are sub-gaussian, we can apply Lemma 3 again.
 For all 
\begin_inset Formula $\delta\ge CR\sqrt{J}\left(\frac{1+\log(C/\sqrt{w})+\kappa\log n}{n_{h}+n_{\ell}}\right)^{1/2}$
\end_inset

, we have for all 
\begin_inset Formula $\ell=1:K$
\end_inset

 and 
\begin_inset Formula $h=1:K$
\end_inset

, (and some constants 
\begin_inset Formula $C,R$
\end_inset

) 
\begin_inset Formula 
\[
Pr_{X_{h},X_{\ell}}\left(\sup_{\lambda}\left|\left\Vert g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right\Vert _{h}^{2}-\left\Vert g^{*}-\hat{g}_{\lambda}(\cdot|D_{-\ell})\right\Vert _{\ell}^{2}\right|\ge\delta\right)\le C\exp\left(-(n_{h}+n_{\ell})\frac{\delta^{2}}{C^{2}R^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Hence for all 
\begin_inset Formula $\lambda\in\Lambda$
\end_inset

, we have with high probability that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\|\hat{g}_{\lambda}(\cdot|D)-\hat{\xi}_{\lambda}\|_{D}^{2}\apprle\sum_{\ell=1}^{K}\left\Vert g^{*}-\hat{g}_{\tilde{\lambda}}(\cdot|D_{-\ell})\right\Vert _{\ell}^{2}+\max_{h,\ell}CR\sqrt{J}\left(\frac{1+\log(C/\sqrt{w})+\kappa\log n}{n_{h}+n_{\ell}}\right)^{1/2}
\]

\end_inset


\end_layout

\begin_layout Subsubsection*

\series bold
Step 3:
\end_layout

\begin_layout Standard
For every 
\begin_inset Formula $k$
\end_inset

, we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
 &  & \|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{D}^{2}\\
 & \le & \sum_{\ell\ne k}\frac{n_{\ell}}{n}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{\ell}^{2}+\frac{n_{k}}{n}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}\\
 & \le & \sum_{\ell\ne k}2\frac{n_{k}}{n}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}+\left(\frac{n_{\ell}}{n}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{\ell}^{2}-\frac{n_{k}}{n}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Using Lemma 3 (and the same arguments given above in Step 2), we get that
 with high probability,
\begin_inset Formula 
\[
\left|\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{\ell}^{2}-\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}\right|\apprle CR\sqrt{J}\left(\frac{1+\log(C/\sqrt{w})+\kappa\log n}{n_{h}+n_{\ell}}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Also, by the definition of 
\begin_inset Formula $\hat{\lambda}$
\end_inset

, the basic inequality gives us that 
\begin_inset Formula 
\begin{eqnarray*}
 &  & \sum_{k=1}^{K}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}\\
 & \le & \sum_{k=1}^{K}\left|\left\langle \epsilon,\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\right\rangle _{k}\right|+\sum_{k=1}^{K}\left|\left\langle g^{*}-\hat{g}_{\tilde{\lambda}}(x|D_{-k}),\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\right\rangle _{k}\right|
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
If the first sum on the RHS (the empirical process term) is bigger, then
 from the same arguments in Step 2, we can bound with high probability that
 
\begin_inset Formula 
\[
\sum_{k=1}^{K}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}\le CR\sqrt{J}\left(\frac{1+\log(C/\sqrt{w})+\kappa\log n}{n_{h}+n_{\ell}}\right)^{1/2}(whp)
\]

\end_inset


\end_layout

\begin_layout Standard
If the second sum on the RHS is bigger, note that by Cauchy-Schwarz 
\begin_inset Formula 
\begin{eqnarray*}
\sum_{k=1}^{K}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2} & \apprle & \sum_{k=1}^{K}\left|\left\langle g^{*}-\hat{g}_{\tilde{\lambda}}(x|D_{-k}),\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\right\rangle _{k}\right|\\
 & \le & \sqrt{\left(\sum_{k=1}^{K}\|g^{*}-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}\right)\left(\sum_{k=1}^{K}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}\right)}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Hence with high probability,
\begin_inset Formula 
\[
\sum_{k=1}^{K}\|\hat{g}_{\hat{\lambda}}(x|D_{-k})-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}\le\sum_{k=1}^{K}\|g^{*}-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}^{2}+CR\sqrt{J}\left(\frac{1+\log(C/\sqrt{w})+\kappa\log n}{n_{h}+n_{\ell}}\right)^{1/2}
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Step 4
\end_layout

\begin_layout Standard
Combining the above steps, we have shown that with high probability, 
\begin_inset Formula 
\[
\|\hat{g}_{\hat{\lambda}}(\cdot|D)-g^{*}\|_{D}\le\max_{h,\ell}CR\sqrt{J}\left(\frac{1+\log(C/\sqrt{w})+\kappa\log n}{n_{h}+n_{\ell}}\right)^{1/2}+\sum_{k=1}^{K}\|g^{*}-\hat{g}_{\tilde{\lambda}}(x|D_{-k})\|_{k}
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore CV converges at a parametric rate modulo a log term plus the optimal
 rates of convergence.
\end_layout

\begin_layout Subsection
Lemmas
\end_layout

\begin_layout Subsubsection
Lemma 0
\end_layout

\begin_layout Standard
Consider any empirical distributions 
\begin_inset Formula $Q_{1}$
\end_inset

 and 
\begin_inset Formula $Q_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Consider the function class 
\begin_inset Formula 
\[
\hat{\mathcal{G}}(Q_{1})=\left\{ \hat{g}_{\lambda}(\cdot|Q_{1})=\arg\min_{g}\frac{1}{2}\|y-g\|_{Q_{1}}^{2}+\lambda P^{v}(g):\lambda\in\Lambda\right\} 
\]

\end_inset


\end_layout

\begin_layout Standard
Suppose the penalty function 
\begin_inset Formula $P$
\end_inset

 is a semi-norm, smooth, and convex.
 Suppose 
\begin_inset Formula $\min_{h:P(h)=1}\|h\|_{Q_{1}}^{2}=O_{p}(n^{-u})$
\end_inset

 and for all 
\begin_inset Formula $h$
\end_inset

, 
\begin_inset Formula $\|h\|_{Q_{2}}\le O_{p}(n^{p})P(h)$
\end_inset

.
 
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $v\ge1$
\end_inset

.
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $\lambda_{min}=O_{P}(n^{-\tau_{min}})$
\end_inset

 and 
\begin_inset Formula $\lambda_{max}=O_{P}(1)$
\end_inset

.
\end_layout

\begin_layout Standard
Then the entropy bound is 
\begin_inset Formula 
\[
H\left(d,\hat{\mathcal{G}},\|\cdot\|_{Q_{2}}\right)\apprle\log\left(\frac{1}{d}\right)+\kappa\log n+\frac{v-1}{v}\log\|\epsilon\|_{Q_{1}}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\kappa=\tau_{min}\frac{v-1}{v}+u+p$
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Proof
\end_layout

\begin_layout Standard
To find the covering number for 
\begin_inset Formula $\hat{\mathcal{G}}$
\end_inset

, we bound the distance
\begin_inset Formula $\|\hat{g}_{\lambda}(\cdot|Q_{1})-\hat{g}_{\lambda+\delta}(\cdot|Q_{1})\|_{Q_{2}}$
\end_inset

 for every 
\begin_inset Formula $\lambda\in\Lambda$
\end_inset

.
\end_layout

\begin_layout Standard
Consider the function 
\begin_inset Formula $h=c\left(\hat{g}_{\lambda}-\hat{g}_{\lambda+\delta}\right)$
\end_inset

 where 
\begin_inset Formula $c>0$
\end_inset

 is some constant s.t.
 
\begin_inset Formula $P(h)=1$
\end_inset

.
 (We'll assume that 
\begin_inset Formula $\|\hat{g}_{\lambda}-\hat{g}_{\lambda+\delta}\|_{Q_{2}}>0$
\end_inset

, since we'll be done otherwise.) Consider the 1-dimensional optimization
 problem
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{m}_{\lambda}(\delta)=\arg\min_{m}\frac{1}{2}\|y-(\hat{g}_{\lambda}+mh)\|_{Q_{1}}^{2}+(\lambda+\delta)P^{v}(\hat{g}_{\lambda}+mh)
\]

\end_inset


\end_layout

\begin_layout Standard
Clearly 
\begin_inset Formula $\hat{m}_{\lambda}(0)=0$
\end_inset

 and 
\begin_inset Formula $\hat{m}_{\lambda}(\delta)=c^{-1}$
\end_inset

.
\end_layout

\begin_layout Standard
Taking the derivative of the criterion wrt 
\begin_inset Formula $m$
\end_inset

, we get
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left.-\langle h,y-(\hat{g}_{\lambda}+mh)\rangle_{Q_{1}}+\lambda\frac{\partial}{\partial m}P^{v}(\hat{g}_{\lambda}+mh)\right|_{m=\hat{m}_{\lambda}(\delta)}=0
\]

\end_inset


\end_layout

\begin_layout Standard
By implicit differentiation wrt 
\begin_inset Formula $\delta$
\end_inset

, we have 
\begin_inset Formula 
\begin{eqnarray*}
\frac{\partial}{\partial\delta}\hat{m}_{\lambda}(\delta) & = & \left.-v\left(\|h\|_{Q_{1}}^{2}+\lambda\frac{\partial^{2}}{\partial m^{2}}P^{v}\left(\hat{g}_{\lambda}+mh\right)\right)^{-1}P^{v-1}(\hat{g}_{\lambda}+mh)\frac{\partial}{\partial m}P(\hat{g}_{\lambda}+mh)\right|_{m=\hat{m}_{\lambda}(\delta)}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
We bound 
\begin_inset Formula $|\frac{\partial}{\partial\delta}\hat{m}(\lambda+\delta)|$
\end_inset

 by bounding each multiplicand.
\end_layout

\begin_layout Standard
1st multiplicand: Since penalty 
\begin_inset Formula $P$
\end_inset

 is convex (regardless of the direction of 
\begin_inset Formula $h$
\end_inset

),
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\left|\|h\|_{T}^{2}+\lambda\frac{\partial^{2}}{\partial m^{2}}P^{v}\left(\hat{g}_{\lambda}+mh\right)\right|^{-1} & \le & \|h\|_{Q_{1}}^{-2}\\
 & \apprle & n^{u}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
2nd multiplicand: By definition of 
\begin_inset Formula $\hat{g}_{\lambda}$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\lambda P^{v}(\hat{g}_{\lambda}+mh)\le\frac{1}{2}\|y-g^{*}\|^{2}+\lambda P^{v}(g^{*})
\]

\end_inset


\end_layout

\begin_layout Standard
Hence
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
P^{v-1}(\hat{g}_{\lambda}+mh) & \le & \left(\frac{1}{2\lambda}\|\epsilon\|_{Q_{1}}+P^{v}(g^{*})\right)^{(v-1)/v}\\
 & \apprle & \left(n^{\tau_{min}}\|\epsilon\|_{Q_{1}}\right)^{(v-1)/v}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
3rd multiplicand: Note that since 
\begin_inset Formula $P$
\end_inset

 is a semi-norm, then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\left|P(\hat{g}_{\lambda}+mh)-P(\hat{g}_{\lambda})\right|\le mP(h)
\]

\end_inset


\end_layout

\begin_layout Standard
Therefore as we take 
\begin_inset Formula $m\rightarrow0$
\end_inset

, we have 
\begin_inset Formula 
\[
\left|\frac{\partial}{\partial m}P(\hat{g}_{\lambda}+mh)\right|\le P(h)
\]

\end_inset


\end_layout

\begin_layout Standard
Conbining the above bounds, we have 
\begin_inset Formula 
\begin{eqnarray*}
\left|\frac{\partial}{\partial\delta}\hat{m}_{\lambda}(\delta)\right| & \apprle & n^{\tau_{min}(v-1)/v+u}\|\epsilon\|_{Q_{1}}^{(v-1)/v}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Using the mean value theorem, there is some 
\begin_inset Formula $\alpha\in[0,1]$
\end_inset

 s.t 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\|\hat{g}_{\lambda}(\cdot|D_{-k})-\hat{g}_{\lambda+\delta}(\cdot|D_{-k})\|_{Q_{2}} & = & \hat{m}_{\lambda}(\delta)\|h\|_{Q_{2}}\\
 & \le & n^{p}\delta\left|\frac{\partial}{\partial a}\hat{m}_{\lambda}(a)\right|_{a=\alpha\delta}\\
 & \le & \delta n^{\tau_{min}(v-1)/v+u+p}\|\epsilon\|_{Q_{1}}^{(v-1)/v}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Therefore the covering number is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
N\left(d,\hat{\mathcal{G}},\|\cdot\|_{Q_{2}}\right)\apprle\frac{1}{d}n^{\tau_{min}(v-1)/v+u+p}\|\epsilon\|_{Q_{1}}^{(v-1)/v}
\]

\end_inset


\end_layout

\begin_layout Standard
so the entropy is 
\begin_inset Formula 
\[
H\left(d,\hat{\mathcal{G}},\|\cdot\|_{Q_{2}}\right)\apprle\log\left(\frac{1}{d}\right)+\left(\tau_{min}\frac{v-1}{v}+u+p\right)\log n+\frac{v-1}{v}\log\|\epsilon\|_{Q_{1}}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Lemma 1
\end_layout

\begin_layout Standard
Define the convex combination 
\begin_inset Formula $\hat{\xi}_{\lambda}(x)=\frac{1}{K-1}\sum_{k=1}^{K}\frac{n-n_{k}}{n}\hat{g}_{\lambda}(x|D_{-k})$
\end_inset

.
 Then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
 &  & \frac{1}{2}\|y-\hat{g}_{\hat{\lambda}}(\cdot|D)\|_{D}^{2}+\hat{\lambda}\left(P(\hat{g}_{\hat{\lambda}}(\cdot|D))+\frac{w}{2}\|\hat{g}_{\hat{\lambda}}(\cdot|D)\|_{D}^{2}\right)\\
 & \ge & \frac{1}{2}\|y-\hat{\xi}_{\hat{\lambda}}\|_{D}^{2}+\hat{\lambda}\left(P(\hat{\xi}_{\hat{\lambda}})+\frac{w}{2}\|\hat{\xi}_{\hat{\lambda}}\|_{D}^{2}\right)+\frac{1}{K-1}\sum_{k=1}^{K}\frac{n-n_{k}}{n}\langle y-\hat{\xi}_{\hat{\lambda}},\hat{\xi}_{\hat{\lambda}}-\hat{g}_{\hat{\lambda}}(\cdot|D_{-k})\rangle_{-k}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
(This is a version of the beginning of the proof for Thrm 1 in Chetverikov,
 Chaterjee probably does the same thing.)
\end_layout

\begin_layout Subsubsection*
Proof
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
 &  & \frac{1}{2}\|y-\hat{g}_{\hat{\lambda}}(\cdot|D)\|_{D}^{2}+\hat{\lambda}\left(P(\hat{g}_{\hat{\lambda}}(\cdot|D))+\frac{w}{2}\|\hat{g}_{\hat{\lambda}}(\cdot|D)\|_{D}^{2}\right)\\
 & = & \frac{1}{K-1}\sum_{k=1}^{K}\frac{n-n_{k}}{n}\left(\frac{1}{2}\|y-\hat{g}_{\hat{\lambda}}(\cdot|D)\|_{-k}^{2}+\hat{\lambda}\left(P(\hat{g}_{\hat{\lambda}}(\cdot|D))+\frac{w}{2}\|\hat{g}_{\hat{\lambda}}(\cdot|D)\|_{-k}^{2}\right)\right)\\
 & \ge & \frac{1}{K-1}\sum_{k=1}^{K}\frac{n-n_{k}}{n}\left(\frac{1}{2}\|y-\hat{g}_{\hat{\lambda}}(\cdot|D_{-k})\|_{-k}^{2}+\hat{\lambda}\left(P(\hat{g}_{\hat{\lambda}}(\cdot|D_{-k}))+\frac{w}{2}\|\hat{g}_{\hat{\lambda}}(\cdot|D_{-k})\|_{-k}^{2}\right)\right)\\
 & \ge & \frac{1}{K-1}\sum_{k=1}^{K}\frac{n-n_{k}}{n}\left(\frac{1}{2}\|y-\hat{g}_{\hat{\lambda}}(\cdot|D_{-k})\|_{-k}^{2}+\hat{\lambda}\frac{w}{2}\|\hat{g}_{\hat{\lambda}}(\cdot|D_{-k})\|_{-k}^{2}\right)+\hat{\lambda}\left(P(\hat{\xi}_{\hat{\lambda}})+\frac{w}{2}\|\hat{\xi}_{\hat{\lambda}}\|_{D}^{2}\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
The second inequality follows by convexity of 
\begin_inset Formula $P$
\end_inset

 and 
\begin_inset Formula $\|\cdot\|^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Now note that 
\begin_inset Formula 
\begin{eqnarray*}
\frac{1}{K-1}\sum_{k=1}^{K}\frac{n-n_{k}}{n}\frac{1}{2}\|y-\hat{g}_{\hat{\lambda}}(\cdot|D_{-k})\|_{-k}^{2} & = & \frac{1}{K-1}\sum_{k=1}^{K}\frac{n-n_{k}}{n}\frac{1}{2}\|y-\hat{\xi}_{\hat{\lambda}}+\hat{\xi}_{\hat{\lambda}}-\hat{g}_{\hat{\lambda}}(\cdot|D_{-k})\|_{-k}^{2}\\
 & \ge & \frac{1}{2}\|y-\hat{\xi}_{\hat{\lambda}}\|_{D}^{2}+\frac{1}{K-1}\sum_{k=1}^{K}\frac{n-n_{k}}{n}\langle y-\hat{\xi}_{\hat{\lambda}},\hat{\xi}_{\hat{\lambda}}-\hat{g}_{\hat{\lambda}}(\cdot|D_{-k})\rangle_{-k}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsubsection
Lemma 2
\end_layout

\begin_layout Standard
Consider any 
\begin_inset Formula $\xi\in\mathcal{G}$
\end_inset

 and 
\begin_inset Formula $\lambda\in\Lambda$
\end_inset

.
 Suppose 
\begin_inset Formula $P$
\end_inset

 is convex.
\end_layout

\begin_layout Standard
Then
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{2}\|\hat{g}_{\lambda}(\cdot|D)-\xi\|_{D}^{2}\le\frac{1}{2}\|y-\xi\|_{D}^{2}-\frac{1}{2}\|y-\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}+\lambda\left(P(\xi)+\frac{w}{2}\|\xi\|_{D}^{2}\right)-\lambda\left(P(\hat{g}_{\lambda}(\cdot|D))+\frac{w}{2}\|\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
(This is a version of Lemma 10 in Chetverikov, which is based on Chaterjee.)
\end_layout

\begin_layout Subsubsection*
Proof
\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $P$
\end_inset

 is convex, then for 
\begin_inset Formula $t\in(0,1)$
\end_inset

, we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
 &  & \frac{1}{2}\|y-\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}+\lambda\left(P(\hat{g}_{\lambda}(\cdot|D))+\frac{w}{2}\|\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}\right)\\
 & \le & \frac{1}{2}\|y-\left(t\xi+(1-t)\hat{g}_{\lambda}(\cdot|D)\right)\|_{D}^{2}+\lambda\left(P(t\xi+(1-t)\hat{g}_{\lambda}(\cdot|D))+\frac{w}{2}\|t\xi+(1-t)\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}\right)\\
 & \le & \frac{1}{2}\|y-\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}+t\langle y-\hat{g}_{\lambda}(\cdot|D),\hat{g}_{\lambda}(\cdot|D)-\xi\rangle_{D}+t^{2}\|\xi-\hat{g}_{\lambda}\|_{D}^{2}+\lambda\left(tP(\xi)+(1-t)P\left(\hat{g}_{\lambda}(\cdot|D)\right)+t\frac{w}{2}\|\xi\|_{D}^{2}+(1-t)\frac{w}{2}\|\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}\right)\\
 & \le & \frac{1}{2}\|y-\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}+t\langle y-\hat{g}_{\lambda}(\cdot|D),\hat{g}_{\lambda}(\cdot|D)-\xi\rangle_{D}+\frac{t^{2}}{2}\|\xi-\hat{g}_{\lambda}\|_{D}^{2}+\lambda\left(tP(\xi)+(1-t)P\left(\hat{g}_{\lambda}(\cdot|D)\right)+t\frac{w}{2}\|\xi\|_{D}^{2}+(1-t)\|\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Rearranging terms, we obain
\begin_inset Formula 
\[
\lambda\left(P\left(\hat{g}_{\lambda}(\cdot|D)\right)+\frac{w}{2}\|\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}-P(\xi)-\frac{w}{2}\|\xi\|_{D}^{2}\right)\le\langle y-\hat{g}_{\lambda}(\cdot|D),\hat{g}_{\lambda}(\cdot|D)-\xi\rangle_{D}+\frac{t}{2}\|\xi-\hat{g}_{\lambda}\|_{D}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Since this is true for any 
\begin_inset Formula $t$
\end_inset

, we have that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\lambda\left(P\left(\hat{g}_{\lambda}(\cdot|D)\right)+\frac{w}{2}\|\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}-P(\xi)-\frac{w}{2}\|\xi\|_{D}^{2}\right)\le\langle y-\hat{g}_{\lambda}(\cdot|D),\hat{g}_{\lambda}(\cdot|D)-\xi\rangle_{D}
\]

\end_inset


\end_layout

\begin_layout Standard
Thus
\begin_inset Formula 
\begin{eqnarray*}
\frac{1}{2}\|\hat{g}_{\lambda}(\cdot|D)-\xi\|_{D}^{2} & \le & \frac{1}{2}\|\hat{g}_{\lambda}(\cdot|D)-y+y-\xi\|_{D}^{2}\\
 & = & \frac{1}{2}\|\hat{g}_{\lambda}(\cdot|D)-y\|_{D}^{2}+\frac{1}{2}\|y-\xi\|_{D}^{2}-\langle\hat{g}_{\lambda}(\cdot|D)-y,\xi-y\rangle_{D}\\
 & = & -\frac{1}{2}\|\hat{g}_{\lambda}(\cdot|D)-y\|_{D}^{2}+\frac{1}{2}\|y-\xi\|_{D}^{2}-\langle\hat{g}_{\lambda}(\cdot|D)-y,\xi-\hat{g}_{\lambda}(\cdot|D)\rangle_{D}\\
 & \le & -\frac{1}{2}\|\hat{g}_{\lambda}(\cdot|D)-y\|_{D}^{2}+\frac{1}{2}\|y-\xi\|_{D}^{2}-\lambda\left(P\left(\hat{g}_{\lambda}(\cdot|D)\right)+\frac{w}{2}\|\hat{g}_{\lambda}(\cdot|D)\|_{D}^{2}-P(\xi)-\frac{w}{2}\|\xi\|_{D}^{2}\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Subsubsection
Lemma 3
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $\epsilon$
\end_inset

 are independent sub-gaussian RV with constants 
\begin_inset Formula $K$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

.
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $X$
\end_inset

 are 
\begin_inset Formula $n$
\end_inset

 random (or fixed) covariate values.
\end_layout

\begin_layout Standard
Suppose for any empirical distribution 
\begin_inset Formula $Q$
\end_inset

, the (random) function class 
\begin_inset Formula $\mathcal{F}(X,\epsilon)$
\end_inset

 has its entropy uniformly bounded 
\begin_inset Formula 
\[
H\left(u,\mathcal{F}(X,\epsilon),\|\cdot\|_{Q}\right)\le\psi(u)=J\left(\log\left(\frac{C}{u\sqrt{w}}\right)+\kappa\log n\right)
\]

\end_inset


\end_layout

\begin_layout Standard
for positive constants 
\begin_inset Formula $J,C,w,\kappa$
\end_inset

.
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $\sup_{f\in\mathcal{F}(X,\epsilon)}\|f\|_{Q}\le R$
\end_inset

.
 
\end_layout

\begin_layout Standard
Then there exists some 
\begin_inset Formula $C$
\end_inset

 s.t.
 for all 
\begin_inset Formula $\delta$
\end_inset

 s.t.
 
\begin_inset Formula $R\ge\delta/\sigma$
\end_inset

 and
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\delta\ge CR\sqrt{J}\left(\frac{1+\log(C/\sqrt{w})+\kappa\log n}{|Q|}\right)^{1/2}
\]

\end_inset


\end_layout

\begin_layout Standard
we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Pr\left(\sup_{f\in\mathcal{F}(X,\epsilon),\|f\|_{Q}\le R}\left|\langle\epsilon,f\rangle_{Q}\right|\ge\delta\wedge\|\epsilon\|_{Q}\le\sigma\right)\le C\exp\left(-|Q|\frac{\delta^{2}}{C^{2}R^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Proof
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\langle\epsilon,\hat{g}_{\lambda}(\cdot|D_{-\ell})-g^{*}\rangle_{-k}
\]

\end_inset


\end_layout

\begin_layout Standard
We apply Lemma 10 in Vandegeer to determine the value 
\begin_inset Formula $\delta$
\end_inset

 s.t.
 
\begin_inset Formula $\delta$
\end_inset

 bounds the empirical process term with high probability.
\end_layout

\begin_layout Standard
For 
\begin_inset Formula $R\ge\delta/\sqrt{2}\sigma$
\end_inset

 ,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\int_{0}^{R}\psi^{1/2}(u)du & = & \sqrt{J}\int_{0}^{R}\left(\log\left(\frac{1}{u}\right)+\log(C/\sqrt{w})+\kappa\log n\right)^{1/2}du\\
 & \apprle & R\sqrt{J}\left(\int_{0}^{1}\log\left(\frac{1}{u}\right)+\log(C/\sqrt{w})+\kappa\log ndu\right)^{1/2}\\
 & \le & R\sqrt{J}\left(1+\log(C/\sqrt{w})+\kappa\log n\right)^{1/2}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Apply Lemma 10 to 
\begin_inset Formula $\delta>0$
\end_inset

 s.t.
 
\begin_inset Formula 
\[
\delta\ge CR\sqrt{J}\left(\frac{1+\log(C/\sqrt{w})+\kappa\log n}{|Q|}\right)^{1/2}
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Lemma 4
\end_layout

\begin_layout Standard
Suppose we are working within a restricted domain, so there is some constant
 
\begin_inset Formula $R$
\end_inset

 s.t.
 
\begin_inset Formula $\|g^{*}\|_{\infty}\le R$
\end_inset

.
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $\epsilon$
\end_inset

 is sub-gaussian with constants 
\begin_inset Formula $K,\sigma$
\end_inset

.
\end_layout

\begin_layout Standard
Then for some constant 
\begin_inset Formula $C$
\end_inset

 that depends on 
\begin_inset Formula $\lambda_{max}$
\end_inset

 and 
\begin_inset Formula $g^{*}$
\end_inset

, we have
\begin_inset Formula 
\[
Pr\left(\sup_{\lambda}\|\hat{g}_{\lambda}(\cdot|D_{-k})-g^{*}\|_{-k}\ge2\sigma+C\right)\le\exp\left(-(n-n_{k})\frac{\sigma^{2}}{12K^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Proof
\end_layout

\begin_layout Standard
By triangle inequality 
\begin_inset Formula 
\[
\|g^{*}-\hat{g}_{\lambda}(\cdot|D_{-k})\|_{-k}\le\|y-\hat{g}_{\lambda}(\cdot|D_{-k})\|_{-k}+\|y-g^{*}\|_{_{-k}}
\]

\end_inset


\end_layout

\begin_layout Standard
By definition of 
\begin_inset Formula $\hat{g}_{\lambda}$
\end_inset

, we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\|y-\hat{g}_{\lambda}(\cdot|D_{-k})\|_{-k}^{2} & \le & \|y-g^{*}\|_{-k}^{2}+\lambda\left(P(g^{*})+\frac{w}{2}\|g^{*}\|_{-k}^{2}\right)\\
 & \le & \|y-g^{*}\|_{-k}^{2}+\lambda_{max}P(g^{*})+\frac{w}{2}R
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\epsilon$
\end_inset

 is sub-gaussian, then by Bernstein's inequality, we have 
\begin_inset Formula 
\[
Pr\left(\|\epsilon\|_{-k}^{2}\ge2\sigma^{2}\right)\le\exp\left(-(n-n_{k})\frac{\sigma^{2}}{12K^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Lemma 10
\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $\epsilon$
\end_inset

 are 
\begin_inset Formula $n$
\end_inset

 independent sub-gaussian RVs with constants 
\begin_inset Formula $K$
\end_inset

 and 
\begin_inset Formula $\sigma$
\end_inset

.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X$
\end_inset

 be 
\begin_inset Formula $n$
\end_inset

 covariate values (potentially randomly drawn).
\end_layout

\begin_layout Standard
Suppose that we have function classes 
\begin_inset Formula $\mathcal{F}(X,\epsilon)$
\end_inset

 dependent on the sub-gaussian RV with entropy 
\begin_inset Formula $H\left(\delta,\mathcal{F}(X,\epsilon),\|\cdot\|_{X}\right)$
\end_inset

.
 Suppose there is a universal bound
\begin_inset Formula 
\[
H\left(u,\mathcal{F}(X,\epsilon),\|\cdot\|_{X}\right)\le\psi(u)
\]

\end_inset


\end_layout

\begin_layout Standard
Suppose 
\begin_inset Formula $\sup_{f\in\mathcal{F}(X,\epsilon)}\|f\|_{X}\le R$
\end_inset

 (with high probability).
 
\end_layout

\begin_layout Standard
Then there exists some 
\begin_inset Formula $C$
\end_inset

 dependent only on 
\begin_inset Formula $K,\sigma$
\end_inset

 s.t.
 for all
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\delta\ge\int_{0}^{R}\psi^{1/2}(u)du
\]

\end_inset


\end_layout

\begin_layout Standard
we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Pr_{\epsilon}\left(\sup_{f_{\theta}\in\mathcal{F}(X,\epsilon)}\left|\langle\epsilon,f_{\theta}\rangle_{X}\right|\ge\delta\wedge\|\epsilon\|_{X}\le\sigma\right)\le C\exp\left(-|X|\frac{\delta^{2}}{C^{2}R^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Proof
\end_layout

\begin_layout Standard
Proof closely follows Lemma 3.2 from Vandegeer.
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $\{f_{j}^{s}(\cdot|\epsilon)\}_{j=1}^{N_{s}}$
\end_inset

 be the 
\begin_inset Formula $2^{-s}R$
\end_inset

-covering set of 
\begin_inset Formula $\mathcal{F}(X,\epsilon)$
\end_inset

 where 
\begin_inset Formula $N_{s}=N_{s}(2^{-s}R,\mathcal{F}(X,\epsilon),X)\le\exp\left(\psi(2^{-s}R)\right)$
\end_inset

.
 Let 
\begin_inset Formula $S=\min\{s:2^{-s}R\le\delta/2\sigma\}$
\end_inset


\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $f_{\theta}^{s}(\cdot|\epsilon)$
\end_inset

 be the closest element to 
\begin_inset Formula $f_{\theta}$
\end_inset

 in the 
\begin_inset Formula $2^{-s}R$
\end_inset

-covering set.
 If 
\begin_inset Formula $\|\epsilon\|_{X}\le\sigma$
\end_inset

, then 
\begin_inset Formula 
\begin{eqnarray*}
\left|\langle\epsilon,f_{\theta}-f_{\theta}^{S}(\cdot|\epsilon)\rangle_{X}\right| & \le & \sigma\|f_{\theta}-f_{\theta}^{S}(\cdot|\epsilon)\|_{X}\\
 & \le & \delta/2
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Therefore it suffices to bound 
\begin_inset Formula 
\[
Pr_{\epsilon}\left(\sup_{j=1:N_{S}}\left|\langle\epsilon,f_{j}^{s}(\cdot|\epsilon)\rangle_{X}\right|\ge\delta/2\wedge\|\epsilon\|_{X}\le\sigma\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Let's chain! Let 
\begin_inset Formula $f_{\theta}^{S}(\cdot|\epsilon)=\sum_{s=1}^{S}f_{\theta}^{s}(\cdot|\epsilon)-f_{\theta}^{s-1}(\cdot|\epsilon)$
\end_inset

.
 Note that
\begin_inset Formula 
\begin{eqnarray*}
\|f_{\theta}^{s}(\cdot|\epsilon)-f_{\theta}^{s-1}(\cdot|\epsilon)\|_{X} & \le & \|f_{\theta}^{s}(\cdot|\epsilon)-f_{\theta}\|_{X}+\|f_{\theta}-f_{\theta}^{s-1}(\cdot|\epsilon)\|_{X}\\
 & \le & 3(2^{-s}R)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Then for some positive numbers s.t.
 
\begin_inset Formula $\sum_{s=1}^{S}\eta_{s}\le1$
\end_inset

, we have 
\begin_inset Formula 
\begin{eqnarray*}
 &  & Pr_{\epsilon}\left(\sup_{j=1:N_{s}}\left|\langle\epsilon,\sum_{s=1}^{S}f_{\theta}^{s}(\cdot|\epsilon)-f_{\theta}^{s-1}(\cdot|\epsilon)\rangle_{X}\right|\ge\delta/2\right)\\
 & \le & \sum_{s=1}^{S}Pr_{\epsilon}\left(\sup_{j=1:N_{s}}\left|\langle\epsilon,f_{\theta}^{s}(\cdot|\epsilon)-f_{\theta}^{s-1}(\cdot|\epsilon)\rangle_{X}\right|\ge\delta/2\eta_{s}\right)\\
 & \le & \sum_{s=1}^{S}\exp\left(2\psi(2^{-s}R)-C\frac{n(\delta/2)^{2}\eta_{s}^{2}}{9(2^{-2s}R^{2})}\right)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Choose 
\begin_inset Formula $\eta_{s}$
\end_inset

 as Vandegeer does.
 Then after a lot of algebraic massaging, we get that for some constants
 
\begin_inset Formula $C_{1},C_{2}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Pr_{\epsilon}\left(\sup_{f_{\theta}\in\mathcal{F}(X,\epsilon)}\left|\langle\epsilon,f_{\theta}\rangle_{X}\right|\ge\delta\wedge\|\epsilon\|_{X}\le\sigma\right)\le C_{1}\exp\left(-|X|\frac{\delta^{2}}{C_{2}^{2}R^{2}}\right)
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
============OLD=========
\end_layout

\begin_layout Standard
Consider any empirical distributions 
\begin_inset Formula $Q_{1}$
\end_inset

 and 
\begin_inset Formula $Q_{2}$
\end_inset

.
\end_layout

\begin_layout Standard
Suppose the penalty function is smooth.
 Suppose 
\begin_inset Formula $O_{p}(n^{-u})=\min_{h:P(h)=1}\|h\|_{D}^{2}$
\end_inset

 and for all 
\begin_inset Formula $h$
\end_inset

,
\begin_inset Formula $\|h\|_{D}\le O_{p}(n^{v})P(h)$
\end_inset

 and 
\begin_inset Formula $\|h\|_{Q_{2}}\le O_{p}(n^{v})P(h)$
\end_inset

.
 Suppose 
\begin_inset Formula $\lambda_{min}=O_{P}(n^{-\tau_{min}})$
\end_inset

 and 
\begin_inset Formula $\lambda_{max}=O_{P}(1)$
\end_inset

.
\end_layout

\begin_layout Standard
Consider the function class 
\begin_inset Formula 
\[
\hat{\mathcal{G}}(Q_{1})=\left\{ \hat{g}_{\lambda}(\cdot|Q_{1}):\lambda\in\Lambda\right\} 
\]

\end_inset

We have that the entropy is bounded at a near-parametric rate:
\begin_inset Formula 
\[
H\left(u,\hat{\mathcal{G}},\|\cdot\|_{Q_{2}}\right)\le\log\left(\frac{C}{u\sqrt{w}}\right)+\kappa\log n
\]

\end_inset


\end_layout

\begin_layout Subsubsection*
Proof
\end_layout

\begin_layout Standard
To find the covering number for 
\begin_inset Formula $\hat{\mathcal{G}}$
\end_inset

, we bound the distance
\begin_inset Formula $\|\hat{g}_{\lambda}(\cdot|Q_{1})-\hat{g}_{\lambda+\delta}(\cdot|Q_{1})\|_{Q_{2}}$
\end_inset

 for every 
\begin_inset Formula $\lambda\in\Lambda$
\end_inset

.
\end_layout

\begin_layout Standard
Consider the function 
\begin_inset Formula $h=c\left(\hat{g}_{\lambda}-\hat{g}_{\lambda+\delta}\right)$
\end_inset

 where 
\begin_inset Formula $c>0$
\end_inset

 is some constant s.t.
 
\begin_inset Formula $P(h)=1$
\end_inset

.
 Consider the 1-dimensional optimization problem
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\hat{m}(\lambda+\delta)=\arg\min_{m}\frac{1}{2}\|y-(\hat{g}_{\lambda}+mh)\|_{Q_{1}}^{2}+(\lambda+\delta)\left(P(\hat{g}_{\lambda}+mh)+\frac{w}{2}\|\hat{g}_{\lambda}+mh\|_{D}^{2}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Clearly 
\begin_inset Formula $\hat{m}_{\lambda}=0$
\end_inset

 and 
\begin_inset Formula $\hat{m}_{\lambda+\delta}=c^{-1}$
\end_inset

.
\end_layout

\begin_layout Standard
Taking the derivative of the criterion wrt 
\begin_inset Formula $m$
\end_inset

, we get
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
-\langle h,y-(\hat{g}_{\lambda}+\hat{m}(\lambda+\delta)h)\rangle_{Q_{1}}+\lambda\left(\frac{\partial}{\partial m}P(\hat{g}_{\lambda}+\hat{m}(\lambda+\delta)h)+w\langle h,g+\hat{m}(\lambda+\delta)h\rangle_{D}\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
By implicit differentiation wrt 
\begin_inset Formula $\delta$
\end_inset

, we have 
\begin_inset Formula 
\[
\frac{\partial}{\partial\delta}\hat{m}(\lambda+\delta)=\left.-\left(\|h\|_{Q_{1}}^{2}+\lambda\frac{\partial^{2}}{\partial m^{2}}P\left(\hat{g}_{\lambda}+mh\right)+\lambda w\|h\|_{D}^{2}\right)^{-1}\left(\frac{\partial}{\partial m}P(\hat{g}_{\lambda}+mh)+w\langle h,\hat{g}_{\lambda}+mh\rangle_{Q_{1}}\right)\right|_{m=\hat{m}(\lambda+\delta)}
\]

\end_inset


\end_layout

\begin_layout Standard
To bound 
\begin_inset Formula $|\frac{\partial}{\partial\delta}\hat{m}(\lambda+\delta)|$
\end_inset

, consider each multiplicand.
\end_layout

\begin_layout Standard
Since penalty 
\begin_inset Formula $P$
\end_inset

 is convex (regardless of the direction of 
\begin_inset Formula $h$
\end_inset

), the first multiplicand is bounded by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\left|\|h\|_{T}^{2}+\lambda\frac{\partial^{2}}{\partial m^{2}}P\left(\hat{g}_{\lambda}+mh\right)+\lambda w\|h\|_{Q_{1}}^{2}\right|^{-1} & \le & \left(\lambda w\|h\|_{Q_{1}}^{2}\right)^{-1}\\
 & \le & \lambda^{-1}w^{-1}O_{P}(n^{u})
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
For the second multiplicand, note that 
\begin_inset Formula 
\[
\left|\frac{\partial}{\partial m}P(\hat{g}_{\lambda}+mh)\right|\le P(h)
\]

\end_inset


\end_layout

\begin_layout Standard
and with high probability,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
w\langle h,\hat{g}_{\lambda}+mh\rangle_{Q_{1}} & \le & w\|h\|_{Q_{1}}\|\hat{g}_{\lambda}+mh\|_{Q_{1}}\\
 & \le & O_{P}(n^{v})w\sqrt{(\lambda w)^{-1}4\sigma^{2}+w^{-1}P(g^{*})+\|g^{*}\|_{Q_{1}}^{2}}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
where we have bounded 
\begin_inset Formula $\|g+m_{\lambda}h\|_{T}$
\end_inset

 using the definition 
\begin_inset Formula 
\[
\frac{\lambda w}{2}\|g+m_{\lambda}h\|_{T}^{2}\le\frac{1}{2}\|y-g^{*}\|_{T}^{2}+\lambda P(g^{*})+\frac{\lambda w}{2}\|g^{*}\|_{Q_{1}}^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
Hence there is a constant 
\begin_inset Formula $C$
\end_inset

 that only depends on 
\begin_inset Formula $g^{*}$
\end_inset

and 
\begin_inset Formula $\sigma$
\end_inset

 s.t.
 
\begin_inset Formula 
\begin{eqnarray*}
\left|\frac{\partial}{\partial\delta}\hat{m}(\lambda+\delta)\right| & = & \lambda^{-1}w^{-1}O_{P}(n^{u})\left|1+O_{P}(n^{v})w\sqrt{(\lambda w)^{-1}4\sigma^{2}+w^{-1}P(g^{*})+\|g^{*}\|_{Q_{1}}^{2}}\right|\\
 & \le & \lambda_{min}^{-1}O_{P}(n^{u+v})\sqrt{(\lambda_{min}w)^{-1}4\sigma^{2}+w^{-1}P(g^{*})+\|g^{*}\|_{Q_{1}}^{2}}\\
 & \le & \frac{O_{P}(n^{1.5\tau_{min}+u+v})}{\sqrt{w}}C
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Using the mean value theorem, there is some 
\begin_inset Formula $\alpha\in[0,1]$
\end_inset

 s.t 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
\|\hat{g}_{\lambda}(\cdot|D_{-k})-\hat{g}_{\lambda+\delta}(\cdot|D_{-k})\|_{Q_{2}} & = & \hat{m}(\lambda+\delta)\|h\|_{Q_{2}}\\
 & \le & n^{-v}\delta\left|\frac{\partial}{\partial u}\hat{m}(\lambda+u)\right|_{u=\alpha\delta}\\
 & \le & \delta\frac{C}{\sqrt{w}}O_{P}(n^{1.5\tau_{min}+u})
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Therefore there is a constant 
\begin_inset Formula $\kappa$
\end_inset

 that linearly grows with 
\begin_inset Formula $u,\tau_{min},\tau_{max}$
\end_inset

 s.t.
 the covering number is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
N\left(u,\hat{\mathcal{G}},\|\cdot\|_{Q_{2}}\right)\le\frac{C}{u\sqrt{w}}O_{p}(n^{\kappa})
\]

\end_inset


\end_layout

\begin_layout Standard
so the entropy is 
\begin_inset Formula 
\[
H\left(u,\hat{\mathcal{G}},\|\cdot\|_{Q_{2}}\right)\le\log\left(\frac{C}{u\sqrt{w}}\right)+\kappa\log n
\]

\end_inset


\end_layout

\begin_layout Standard
============NEW?===================
\end_layout

\end_body
\end_document
