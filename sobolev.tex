%% LyX 2.1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=3cm,bmargin=3cm,lmargin=3cm,rmargin=3cm}
\usepackage{esint}
\usepackage{babel}
\begin{document}

\subsection*{Sobolev penalty:univariate}

The Sobolev penalty is

\[
P(h)=\int(h^{(r)}(x))^{2}dx
\]


Suppose $\sup_{g}\|g\|_{\infty}\le G$.

We shall suppose for simplicity that the domain is $[0,1]$.

Suppose we have the function class (so no additional ridge penalty)
\[
\hat{\mathcal{G}}(T)=\left\{ \hat{g}(\cdot|\lambda)=\arg\min_{g\in\mathcal{G}}\frac{1}{2}\|y-g\|_{T}^{2}+\lambda P(g):\lambda\in\Lambda\right\} 
\]


Using the logic in Example 9.3.2 in Vandegeer, we can express any
function in $\mathcal{G}$ as 
\[
f+g
\]
where 
\[
g=\sum_{k=1}^{r}\alpha_{k}\psi_{k},f=\int_{0}^{1}\beta_{u}\tilde{\phi}_{u}
\]


where $\langle\psi_{k},\tilde{\phi}_{u}\rangle_{T}=0$ and $P(\psi_{k})=0$.

Suppose the observations were drawn from $y=f^{*}+g^{*}+\epsilon$.

Now we have the function class

\[
\hat{\mathcal{G}}(T)=\left\{ \hat{g}(\cdot|\lambda),\hat{f}(\cdot|\lambda)=\arg\min_{g\in\mathcal{G}}\frac{1}{2}\|y-(f+g)\|_{T}^{2}+\lambda P(f):\lambda\in\Lambda,g=\sum_{k=1}^{r}\alpha_{k}\psi_{k},f=\int_{0}^{1}\beta_{u}\tilde{\phi}_{u}\right\} 
\]


We will show that
\begin{eqnarray*}
\left\Vert \left(\hat{g}(\cdot|\lambda^{(1)})+\hat{f}(\cdot|\lambda^{(1)})\right)-\left(\hat{g}(\cdot|\lambda^{(2)})+\hat{f}(\cdot|\lambda^{(2)})\right)\right\Vert _{\infty} & \le & |\lambda^{(1)}-\lambda^{(2)}|n^{\tau_{min}}\sqrt{\frac{n^{\tau_{min}}}{2}\|\epsilon\|_{T}^{2}+P(f^{*})}G
\end{eqnarray*}



\subsubsection*{Proof}

First by Vandegeer Example 9.3.2, we know that 
\[
\hat{g}(\cdot|\lambda)=\arg\min_{g=\sum\alpha_{k}\psi_{k}}-2\langle\epsilon,g-g^{*\perp}\rangle_{T}+\|g-g^{*}\|_{T}^{2}
\]


\[
\hat{f}(\cdot|\lambda)=\arg\min_{f=\int_{0}^{1}\beta_{u}\tilde{\phi}_{u}}-2\langle\epsilon,f-f^{*}\rangle_{T}+\|f-f^{*}\|_{T}^{2}+\lambda P(f)
\]


So $\hat{g}(\cdot|\lambda)$ is actually independent of $\lambda$
and is therefore constant. We will just denote it $\hat{g}$ from
now on.

Now consider 
\[
h=c\left(\hat{f}(\cdot|\lambda^{(1)})-\hat{f}(\cdot|\lambda^{(2)})\right)
\]
 where $c$ is some constant s.t. $P(h)=1$.

We can assume that $P(h)\ne0$. Otherwise, if 
\begin{eqnarray*}
P\left(\hat{f}(\cdot|\lambda^{(1)})-\hat{f}(\cdot|\lambda^{(2)})\right) & = & 0
\end{eqnarray*}
then we know that
\[
\hat{f}(\cdot|\lambda^{(1)})-\hat{f}(\cdot|\lambda^{(2)})\in span\left\{ \psi_{k}\right\} _{k=1}^{r}
\]


This is true if and only if $\hat{f}(\cdot|\lambda^{(1)})\equiv\hat{f}(\cdot|\lambda^{(2)})$
(by the fact that the function spaces are orthogonal).

Consider the optimization problem

\[
\hat{m}_{h}(\lambda)=\arg\min_{m}\frac{1}{2}\|y-(\hat{g}+\hat{f}(\cdot|\lambda^{(1)})+mh)\|_{T}^{2}+\lambda P\left(\hat{f}(\cdot|\lambda^{(1)})+mh\right)
\]


By implicit differentiation of the KKT conditions, we get
\begin{eqnarray*}
\frac{\partial}{\partial\lambda}\hat{m}_{h}(\lambda) & = & \left.-\left(\|h\|_{T}^{2}+\lambda\frac{\partial^{2}}{\partial m^{2}}P\left(\hat{f}(\cdot|\lambda^{(1)})+mh\right)\right)^{-1}\frac{\partial}{\partial m}P\left(\hat{f}(\cdot|\lambda^{(1)})+mh\right)\right|_{m=\hat{m}_{\lambda}(\lambda_{0})}
\end{eqnarray*}


Then the first multiplicand is bounded by 
\begin{eqnarray*}
\left|\|h\|_{T}^{2}+\lambda\frac{\partial^{2}}{\partial m^{2}}P\left(\hat{f}(\cdot|\lambda^{(1)})+mh\right)\right|^{-1} & \le & n^{\tau_{min}}\frac{\partial^{2}}{\partial m^{2}}P\left(\hat{f}(\cdot|\lambda^{(1)})+mh\right)^{-1}\\
 & = & \frac{n^{\tau_{min}}}{2P(h)}
\end{eqnarray*}


The equality follows from the Lemma Sobolev Facts (see below).

From the Lemma Sobolev Facts and by the fact that $P(h)=1$, we have
\begin{eqnarray*}
\left|\frac{\partial}{\partial\lambda}\hat{m}_{h}(\lambda)\right| & \le & \frac{n^{\tau_{min}}}{P(h)}\sqrt{P\left(\hat{f}(\cdot|\lambda^{(1)})+mh\right)P(h)}\\
 & = & n^{\tau_{min}}\sqrt{P\left(\hat{f}(\cdot|\lambda^{(1)})+mh\right)}
\end{eqnarray*}


We know that
\begin{eqnarray*}
\lambda P\left(\hat{f}(\cdot|\lambda^{(1)})+mh\right) & \le & \frac{1}{2}\|y-(\hat{g}+\hat{f}(\cdot|\lambda^{(1)}))\|_{T}^{2}+\lambda P\left(\hat{f}(\cdot|\lambda^{(1)})\right)\\
 & \le & \frac{1}{2}\|y-(g^{*}+f^{*})\|_{T}^{2}+\lambda^{(1)}P\left(f^{*}\right)+\left(\lambda-\lambda^{(1)}\right)P\left(\hat{f}(\cdot|\lambda^{(1)})\right)
\end{eqnarray*}


and 
\[
P\left(\hat{f}(\cdot|\lambda^{(1)})\right)\le\frac{1}{2\lambda^{(1)}}\|y-(g^{*}+f^{*})\|_{T}^{2}+P\left(f^{*}\right)
\]


So 
\[
P\left(\hat{f}(\cdot|\lambda^{(1)})+mh\right)\le\frac{n^{\tau_{min}}}{2}\|\epsilon\|_{T}^{2}+P(f^{*})
\]


Then by the MVT, we have 
\begin{eqnarray*}
\|\hat{f}(\cdot|\lambda^{(1)})-\hat{f}(\cdot|\lambda^{(2)})\|_{\infty} & = & \|m_{h}(\lambda)h\|_{\infty}\\
 & \le & |\lambda^{(1)}-\lambda^{(2)}|\left|\frac{\partial}{\partial\lambda}\hat{m}_{h}(\lambda)\right|G\\
 & \le & |\lambda^{(1)}-\lambda^{(2)}|n^{\tau_{min}}\sqrt{\frac{n^{\tau_{min}}}{2}\|\epsilon\|_{T}^{2}+P(f^{*})}G
\end{eqnarray*}



\subsection*{Sobolev penalty: multivariate}

The function class of interest

\[
\hat{\mathcal{G}}(T)=\left\{ \left\{ \hat{g}_{j}(\cdot|\lambda),\hat{f}_{j}(\cdot|\lambda)\right\} =\arg\min_{g\in\mathcal{G}}\frac{1}{2}\|y-\sum_{j=1}^{J}g_{j}(x_{j})\|_{T}^{2}+\sum_{j=1}^{J}\lambda_{j}P(g_{j}):\lambda\in\Lambda\right\} 
\]


We conclude the same thing


\subsubsection*{Proof}

First by Vandegeer Example 9.3.2, we know that 
\[
\left\{ \hat{g}_{j}(\cdot|\lambda)\right\} =\arg\min_{g_{j}=\sum\alpha_{k}\psi_{k}}-2\langle\epsilon,\sum_{j=1}^{J}g_{j}-g_{j}^{*}\rangle_{T}+\|\sum_{j=1}^{J}g_{j}-g_{j}^{*}\|_{T}^{2}
\]


\[
\left\{ \hat{f}_{j}(\cdot|\lambda)\right\} =\arg\min_{f_{j}=\int_{0}^{1}\beta_{u}\tilde{\phi}_{u}}-2\langle\epsilon,\sum_{j=1}^{J}f_{j}-f_{j}^{*}\rangle_{T}+\|\sum_{j=1}^{J}f_{j}-f_{j}^{*}\|_{T}^{2}+\sum_{j=1}^{J}\lambda_{j}P(f_{j})
\]


So $\hat{g}(\cdot|\lambda)$ is actually independent of $\lambda$
and is therefore constant. We will just denote it $\hat{g}_{j}$ from
now on.

Now consider 
\[
h_{j}=c\left(\hat{f}_{j}(\cdot|\lambda^{(1)})-\hat{f}_{j}(\cdot|\lambda^{(2)})\right)
\]
 where $c$ is some constant s.t. $P(h_{j})=1$.

We can assume that $P(h_{j})\ne0$. Otherwise, if 
\begin{eqnarray*}
P\left(\hat{f}_{j}(\cdot|\lambda^{(1)})-\hat{f}_{j}(\cdot|\lambda^{(2)})\right) & = & 0
\end{eqnarray*}
then we know that
\[
\hat{f}_{j}(\cdot|\lambda^{(1)})-\hat{f}_{j}(\cdot|\lambda^{(2)})\in span\left\{ \psi_{k}\right\} _{k=1}^{r}
\]


This is true if and only if $\hat{f}_{j}(\cdot|\lambda^{(1)})\equiv\hat{f}_{j}(\cdot|\lambda^{(2)})$
(by the fact that the function spaces are orthogonal).

Now consider the optimization problem

\[
\left\{ \hat{m}_{j}(\lambda,h)\right\} =\arg\min_{m_{j}}\frac{1}{2}\|y-\sum_{j=1}^{J}(\hat{g}_{j}+\hat{f}_{j}(\cdot|\lambda^{(1)})+m_{j}h_{j})\|_{T}^{2}+\lambda P\left(\hat{f}_{j}(\cdot|\lambda^{(1)})+m_{j}h_{j}\right)
\]


(If $h_{j}\equiv0$, then set $m_{j}=0$ as a constant.) For simplicity,
we will assume $h_{j}\ne0$.

By implicit differentiation of the KKT conditions, we get for all
$\ell=1:J$
\begin{eqnarray*}
\frac{\partial}{\partial\lambda_{\ell}}\hat{m}_{\ell}(\lambda,h) & = & \left.-\left(\|h\|_{T}^{2}+\sum_{j=1}^{J}\lambda_{j}\frac{\partial^{2}}{\partial m_{j}^{2}}P\left(\hat{f}_{j}(\cdot|\lambda^{(1)})+m_{j}h_{j}\right)\right)^{-1}\frac{\partial}{\partial m_{\ell}}P\left(\hat{f}_{\ell}(\cdot|\lambda^{(1)})+m_{\ell}h\right)\right|_{m=\hat{m}(\lambda,h)}
\end{eqnarray*}


and 
\[
\frac{\partial}{\partial\lambda_{k}}\hat{m}_{\ell}(\lambda,h)=0\mbox{ if }\ell\ne k
\]


From the Lemma Sobolev Facts, we have
\begin{eqnarray*}
\left|\frac{\partial}{\partial\lambda}\hat{m}_{h}(\lambda)\right| & \le & \frac{n^{\tau_{min}}}{P(h_{\ell})}\sqrt{P\left(\hat{f}_{\ell}(\cdot|\lambda^{(1)})+m_{\ell}h_{\ell}\right)P(h_{\ell})}\\
 & = & n^{\tau_{min}}\sqrt{P\left(\hat{f}_{\ell}(\cdot|\lambda^{(1)})+m_{\ell}h_{\ell}\right)}
\end{eqnarray*}


We know that
\begin{eqnarray*}
\lambda_{\ell}P\left(\hat{f}_{\ell}(\cdot|\lambda^{(1)})+m_{\ell}h_{\ell}\right) & \le & \frac{1}{2}\|y-(\hat{g}+\hat{f}(\cdot|\lambda^{(1)}))\|_{T}^{2}+\sum_{j=1}^{J}\lambda_{j}P\left(\hat{f}(\cdot|\lambda^{(1)})\right)\\
 & \le & \frac{1}{2}\|y-(g^{*}+f^{*})\|_{T}^{2}+\sum_{j=1}^{J}\lambda_{j}^{(1)}P\left(f^{*}\right)+\sum_{j=1}^{J}\left(\lambda_{j}-\lambda_{j}^{(1)}\right)P\left(\hat{f}(\cdot|\lambda^{(1)})\right)
\end{eqnarray*}


and 
\[
P\left(\hat{f}_{\ell}(\cdot|\lambda^{(1)})\right)\le\frac{1}{2\lambda_{\ell}^{(1)}}\|y-(g^{*}+f^{*})\|_{T}^{2}+\sum_{j=1}^{J}\lambda_{j}^{(1)}P\left(f^{*}\right)
\]


So 
\[
P\left(\hat{f}_{\ell}(\cdot|\lambda^{(1)})+m_{\ell}h_{\ell}\right)\le\frac{n^{\tau_{min}}}{2}\|\epsilon\|_{T}^{2}+n^{t_{\max}+t_{\min}}\sum_{j=1}^{J}P\left(f^{*}\right)
\]


Then by the MVT, we have 
\begin{eqnarray*}
\|\hat{f}_{\ell}(\cdot|\lambda^{(1)})-\hat{f}_{\ell}(\cdot|\lambda^{(2)})\|_{\infty} & = & \|\hat{m}_{\ell}(\lambda,h)h_{\ell}\|_{\infty}\\
 & \le & \left\Vert \lambda^{(1)}-\lambda^{(2)}\right\Vert \left\Vert \nabla_{\lambda}\hat{m}_{\ell}(\lambda,h)\right\Vert G\\
 & \le & \left\Vert \lambda^{(1)}-\lambda^{(2)}\right\Vert n^{\tau_{min}}\sqrt{\frac{n^{\tau_{min}}}{2}\|\epsilon\|_{T}^{2}+n^{t_{\max}+t_{\min}}\sum_{j=1}^{J}P\left(f^{*}\right)}G
\end{eqnarray*}



\subsubsection*{Lemma: Sobolev Facts}

For any function $h$, we have
\begin{eqnarray*}
\left|\frac{\partial}{\partial m}P(g+mh)\right| & = & \left|2\int(g^{(r)}(x)+mh^{(r)}(x))h^{(r)}(x)dx\right|\\
 & \le & 2\sqrt{P(g+mh)P(h)}
\end{eqnarray*}


and 
\[
\frac{\partial^{2}}{\partial m^{2}}P(g+mh)=2\int(h^{(r)}(x))^{2}dx=2P(h)
\]

\end{document}
